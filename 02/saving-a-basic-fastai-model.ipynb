{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30185,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Saving a Cats v Dogs Model","metadata":{"id":"98d53c05"}},{"cell_type":"markdown","source":"This is a minimal example showing how to train a fastai model on Kaggle, and save it so you can use it in your app.","metadata":{}},{"cell_type":"code","source":"# Make sure we've got the latest version of fastai:\n!pip install -Uqq fastai gradio","metadata":{"id":"evvA0fqvSblq","outputId":"ba21b811-767c-459a-ccdf-044758720a55","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-02T14:48:05.593906Z","iopub.execute_input":"2024-04-02T14:48:05.594202Z","iopub.status.idle":"2024-04-02T14:48:35.578825Z","shell.execute_reply.started":"2024-04-02T14:48:05.594169Z","shell.execute_reply":"2024-04-02T14:48:35.577995Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\ntensorflow 2.6.3 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\ntensorflow 2.6.3 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.3 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.3 requires wrapt~=1.12.1, but you have wrapt 1.14.0 which is incompatible.\ntensorflow-transform 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\ntensorflow-transform 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.3 which is incompatible.\nrich 12.2.0 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.6.1 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytools 2022.1.5 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\njupytext 1.13.7 requires markdown-it-py~=1.0, but you have markdown-it-py 2.2.0 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\ncached-path 1.1.2 requires huggingface-hub<0.6.0,>=0.0.12, but you have huggingface-hub 0.16.4 which is incompatible.\napache-beam 2.37.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\napache-beam 2.37.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\napache-beam 2.37.0 requires pyarrow<7.0.0,>=0.15.1, but you have pyarrow 7.0.0 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.2.0 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"First, import all the stuff we need from fastai:","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"44eb0ad3","execution":{"iopub.status.busy":"2024-04-02T14:42:19.907504Z","iopub.execute_input":"2024-04-02T14:42:19.908331Z","iopub.status.idle":"2024-04-02T14:42:22.696205Z","shell.execute_reply.started":"2024-04-02T14:42:19.908290Z","shell.execute_reply":"2024-04-02T14:42:22.695458Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Download and decompress our dataset, which is pictures of dogs and cats:","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\npath = untar_data(URLs.PETS)/'images'\ndef is_cat(x): return x[0].isupper() \ndls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat,\n    item_tfms=Resize(192))\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(1)\nlearn.path = Path('.')\nlearn.export()\n\nimport gradio as gr\nlearn = load_learner('export.pkl')\nlabels = learn.dls.vocab\ndef predict(img):\n    img = PILImage.create(img)\n    pred,pred_idx,probs = learn.predict(img)\n    return {labels[i]: float(probs[i]) for i in range(len(labels))}\n\n\nimport gradio as gr\ngr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=gr.outputs.Label(num_top_classes=3)).queue().launch(share=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:48:39.808466Z","iopub.execute_input":"2024-04-02T14:48:39.809336Z","iopub.status.idle":"2024-04-02T14:50:39.084092Z","shell.execute_reply.started":"2024-04-02T14:48:39.809282Z","shell.execute_reply":"2024-04-02T14:50:39.083134Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [811712512/811706944 00:21<00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84857d8f4d0b4a0ea5ff8c7c7e4d7738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.179735</td>\n      <td>0.057922</td>\n      <td>0.020298</td>\n      <td>00:37</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.071514</td>\n      <td>0.038386</td>\n      <td>0.011502</td>\n      <td>00:32</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/gradio/inputs.py:260: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n/opt/conda/lib/python3.7/site-packages/gradio/inputs.py:270: UserWarning: `optional` parameter is deprecated, and it has no effect\n  optional=optional,\n/opt/conda/lib/python3.7/site-packages/gradio/outputs.py:198: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  \"Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\",\n/opt/conda/lib/python3.7/site-packages/gradio/outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n","output_type":"stream"},{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://31d696ee426186cbbe.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://31d696ee426186cbbe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"markdown","source":"We need a way to label our images as dogs or cats. In this dataset, pictures of cats are given a filename that starts with a capital letter:","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"44eb0ad3","execution":{"iopub.status.busy":"2024-04-02T14:38:44.370211Z","iopub.execute_input":"2024-04-02T14:38:44.370997Z","iopub.status.idle":"2024-04-02T14:38:44.375473Z","shell.execute_reply.started":"2024-04-02T14:38:44.370949Z","shell.execute_reply":"2024-04-02T14:38:44.374567Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Now we can create our `DataLoaders`:","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"44eb0ad3","execution":{"iopub.status.busy":"2024-04-02T14:38:46.073310Z","iopub.execute_input":"2024-04-02T14:38:46.073585Z","iopub.status.idle":"2024-04-02T14:38:46.691158Z","shell.execute_reply.started":"2024-04-02T14:38:46.073554Z","shell.execute_reply":"2024-04-02T14:38:46.690383Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"... and train our model, a resnet18 (to keep it small and fast):","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"c107f724","outputId":"fcc1de68-7c8b-43f5-b9eb-fcdb0773ef07","execution":{"iopub.status.busy":"2024-04-02T14:38:49.436901Z","iopub.execute_input":"2024-04-02T14:38:49.437179Z","iopub.status.idle":"2024-04-02T14:39:42.924760Z","shell.execute_reply.started":"2024-04-02T14:38:49.437147Z","shell.execute_reply":"2024-04-02T14:39:42.923928Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.180818</td>\n      <td>0.078668</td>\n      <td>0.022327</td>\n      <td>00:26</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.072440</td>\n      <td>0.033032</td>\n      <td>0.009472</td>\n      <td>00:26</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can export our trained `Learner`. This contains all the information needed to run the model:","metadata":{}},{"cell_type":"code","source":"# learn.export('model.pkl')","metadata":{"id":"ae2bc6ac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:40:01.722585Z","iopub.execute_input":"2024-04-02T14:40:01.723410Z","iopub.status.idle":"2024-04-02T14:40:01.899370Z","shell.execute_reply.started":"2024-04-02T14:40:01.723354Z","shell.execute_reply":"2024-04-02T14:40:01.898592Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:40:04.041331Z","iopub.execute_input":"2024-04-02T14:40:04.042129Z","iopub.status.idle":"2024-04-02T14:40:04.089910Z","shell.execute_reply.started":"2024-04-02T14:40:04.042079Z","shell.execute_reply":"2024-04-02T14:40:04.089124Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-02T14:47:49.419072Z","iopub.execute_input":"2024-04-02T14:47:49.419356Z","iopub.status.idle":"2024-04-02T14:47:49.512326Z","shell.execute_reply.started":"2024-04-02T14:47:49.419281Z","shell.execute_reply":"2024-04-02T14:47:49.511440Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3432266836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'export.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'"],"ename":"ModuleNotFoundError","evalue":"No module named 'gradio'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, open the Kaggle sidebar on the right if it's not already, and find the section marked \"Output\". Open the `/kaggle/working` folder, and you'll see `model.pkl`. Click on it, then click on the menu on the right that appears, and choose \"Download\". After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model.","metadata":{"id":"Q2HTrQKTf3BV"}}]}